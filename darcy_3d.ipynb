{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3278e3",
   "metadata": {},
   "source": [
    "### Darcy Advect-diffuse net\n",
    "\n",
    "Implement the MR-AIV pipeline in [J. D. Toscano et al. 2025](https://doi.org/10.1101/2025.07.30.667741) using pytorch + lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First choose a config file to apply\n",
    "config_path = \"configs/dcpinn_sphere_test.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e4cbe",
   "metadata": {},
   "source": [
    "#### 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from modules.dc_net import AD_DC_Net\n",
    "from modules.data_module import CharacteristicDomain, DCEMRIDataModule, VelocityDataModule, PermeabilityDataModule\n",
    "from modules.filtered_modules import create_outlier_filter_mask, FilteredDCEMRIDataModule\n",
    "\n",
    "from utils.config_loader import Train_Config\n",
    "from utils.train_wrapper import train_all_phases\n",
    "from utils.visualize import draw_nifti_slices_with_time, draw_nifti_slices_with_threshold, interactive_quiver\n",
    "from utils.io import load_dcemri_data, save_velocity_mat, load_DTI\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# load cfg from yaml path.\n",
    "cfg = Train_Config(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data,mask,pixdim,x,y,z,t = load_dcemri_data(cfg.dcemrinp_data_path)\n",
    "\n",
    "\n",
    "char_domain = CharacteristicDomain(data.shape, mask, t, pixdim, cfg.reload_dataloaders_every_n_epochs, cfg.device)\n",
    "\n",
    "print(\"L_star: \",char_domain.L_star, \"T_star: \", char_domain.T_star)\n",
    "# batch_size is sum over data's point\n",
    "c_dataset = DCEMRIDataModule(data, char_domain,  \n",
    "                           batch_size=int(mask.sum()*len(t)), num_workers=cfg.dataset_num_workers, device=cfg.device)\n",
    "\n",
    "# set up to get num_train_points\n",
    "c_dataset.setup()\n",
    "print(\"num_train_points: \", c_dataset.num_train_points, \"batch_size: \", c_dataset.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a9e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = torch.load(cfg.ckpt_path, map_location=cfg.device)\n",
    "# ckpt['state_dict']['ad_dc_net._log_Pe'] = torch.log(torch.as_tensor(char_domain.V_star.mean() * char_domain.L_star.mean() / 2e-3, dtype=torch.float32))\n",
    "# torch.save(ckpt, cfg.ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# already converted to characteristic domain\n",
    "if cfg.use_DTI:\n",
    "    DTI_tensor, DTI_tensor_raw,DTI_MD = load_DTI(char_domain, cfg.dti_data_path, data.shape[:3])\n",
    "else:\n",
    "    DTI_tensor = None\n",
    "\n",
    "char_domain.set_DTI_or_coef(DTI_tensor if cfg.use_DTI else 2.4e-4)\n",
    "print(\"Pe_g: \", char_domain.Pe_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622bf29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.use_DTI:\n",
    "    draw_nifti_slices_with_threshold(DTI_MD, brain_mask=mask, slice_along_axis='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use front-tracking to get initial velocity field.\n",
    "from utils.velocity_guess import front_tracking_velocity\n",
    "# shape (nx, ny, nz, 3), only use half of data for estimation, unit in cell/min\n",
    "initial_velocity_field = front_tracking_velocity(data[:,:,:,::2], \n",
    "                                                 dt=t[2] - t[0])\n",
    "# draw initial velocity magnitude\n",
    "vel_mag = np.linalg.norm(initial_velocity_field, axis=-1)\n",
    "# print(pixdim, char_domain.domain_shape, char_domain.L_star, char_domain.T_star, char_domain.V_star)\n",
    "print(\"velocity max and min: \", vel_mag.max(), vel_mag.min())\n",
    "draw_nifti_slices_with_threshold(vel_mag)\n",
    "\n",
    "v_dataset = VelocityDataModule(initial_velocity_field, char_domain,\n",
    "                              batch_size=int(mask.sum()), num_workers=cfg.dataset_num_workers, device=cfg.device)\n",
    "# scaling, front tracking give unit in cell/min, we need to scale to characteristic velocity\n",
    "\n",
    "# set up to get num_train_points\n",
    "v_dataset.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720de574",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_quiver(initial_velocity_field[:,:,:,0], initial_velocity_field[:,:,:,1], \n",
    "                   initial_velocity_field[:,:,:,2], char_domain.pixdim,default_elev=-62.76, default_azim=-10.87)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of interactive_quiver, using simulation\n",
    "from utils.forward_sim import advect_diffuse_forward_simulation\n",
    "\n",
    "sim_frame_num = 10\n",
    "sim_steps_per_frame = 10 * int(t[1] - t[0])\n",
    "# WARNING: here we can only enable diffusion / advection, \n",
    "# to check whether we has a good init of both velocity and diffusivity.\n",
    "using_v, using_D = initial_velocity_field, DTI_tensor_raw/3.0 if cfg.use_DTI else 2.4e-4\n",
    "# using_v, using_D = np.zeros_like(initial_velocity_field), DTI_tensor/3.0 if cfg.use_DTI else 2.4e-4\n",
    "frames = advect_diffuse_forward_simulation(data[:,:,:,0] / c_dataset.C_star, using_v[:,:,:,0],\n",
    "                using_v[:,:,:,1],\n",
    "                using_v[:,:,:,2],\n",
    "                D=using_D, total_time=sim_frame_num * int(t[1] - t[0]), num_steps=sim_steps_per_frame*sim_frame_num,\n",
    "                voxel_dims=(1.0,1.0,1.0))\n",
    "frames = np.array(frames).transpose(1,2,3,0)\n",
    "# jump sim_steps_per_frame to match time points\n",
    "frames = frames[:,:,:,::sim_steps_per_frame]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888506e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frames.shape,data[:,:,:,:sim_frame_num+1].shape)\n",
    "# compare with ground truth\n",
    "_ = draw_nifti_slices_with_time(frames, gt_imgs=data[:,:,:,:sim_frame_num+1] / c_dataset.C_star, brain_mask=mask, slice_along_axis='z', percentiles=(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f21f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.permeability_guess import estimate_initial_permeability\n",
    "\n",
    "initial_permeability, smooth_permeability = estimate_initial_permeability(data, t, ser_threshold=12.0,\n",
    "                                                     time_threshold_min=t[4])\n",
    "print(\"Initial permeability max and min: \", smooth_permeability.max(), smooth_permeability.min())\n",
    "draw_nifti_slices_with_threshold(smooth_permeability, brain_mask=mask)\n",
    "# prepare permeability datamodule, according to the paper,\n",
    "# \"smooth\" initial permeability guess is almost certainly the better and safer choice for initializing the NN_k network\n",
    "k_dataset = PermeabilityDataModule(smooth_permeability, char_domain,\n",
    "                                  batch_size=int(mask.sum()), num_workers=cfg.dataset_num_workers, device=cfg.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d580f",
   "metadata": {},
   "source": [
    "#### 2. Network definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4303f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.c_trainer import CNet_Init, CNet_DenoiseInit\n",
    "\n",
    "from modules.dc_trainer import DCPINN_InitK, DCPINN_InitP, DCPINN_ADPDE_P, DCPINN_ADPDE_P_K, DCPINN_Joint\n",
    "\n",
    "# write a trainner getter to factorize.\n",
    "\n",
    "def DCPINN_trainer_getter(train_phase, ad_dc_net, phase_cfg={}):\n",
    "    global c_dataset\n",
    "    incompressible = phase_cfg.get(\"incompressible\", False)\n",
    "    enable_td_weight = phase_cfg.get(\"enable_td_weight\", True)\n",
    "\n",
    "    if train_phase == CNet_Init.train_phase:\n",
    "        pinn_model = CNet_Init(ad_dc_net.c_net, c_dataset.num_train_points)\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == CNet_DenoiseInit.train_phase:\n",
    "        pinn_model = CNet_DenoiseInit(ad_dc_net.c_net, c_dataset.num_train_points)\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == DCPINN_InitK.train_phase:\n",
    "        pinn_model = DCPINN_InitK(ad_dc_net, k_dataset.num_train_points)\n",
    "        datamodule = k_dataset\n",
    "    elif train_phase == DCPINN_InitP.train_phase:\n",
    "        pinn_model = DCPINN_InitP(ad_dc_net, v_dataset.num_train_points)\n",
    "        datamodule = v_dataset\n",
    "    elif train_phase == \"filter\":\n",
    "        batch_size = phase_cfg.get(\"batch_size\", 200_000)\n",
    "        # filter means filter on c_dataset.\n",
    "        ad_dc_net.c_net.to(cfg.device)\n",
    "        valid_mask = create_outlier_filter_mask(ad_dc_net.c_net, c_dataset.X_train, cfg.result_folder, batch_size)\n",
    "        c_dataset = FilteredDCEMRIDataModule(c_dataset, valid_mask)\n",
    "        c_dataset.setup() # setup to get actual train_num_points\n",
    "        pinn_model = None\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == DCPINN_ADPDE_P.train_phase:\n",
    "        pinn_model = DCPINN_ADPDE_P(ad_dc_net, c_dataset.num_train_points, \n",
    "                                    incompressible=incompressible,\n",
    "                                    enable_td_weight=enable_td_weight)\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == DCPINN_ADPDE_P_K.train_phase:\n",
    "        pinn_model = DCPINN_ADPDE_P_K(ad_dc_net, c_dataset.num_train_points, \n",
    "                                      incompressible=incompressible,\n",
    "                                      enable_td_weight=enable_td_weight)\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == DCPINN_Joint.train_phase:\n",
    "        pinn_model = DCPINN_Joint(ad_dc_net, c_dataset.num_train_points, incompressible=incompressible,\n",
    "                                   enable_td_weight=enable_td_weight)\n",
    "        datamodule = c_dataset\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown train_phase {train_phase}\")\n",
    "    return pinn_model, datamodule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39415700",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_star = np.mean(char_domain.V_star * cfg.viscosity * char_domain.L_star / k_dataset.K_star)\n",
    "print(\"P_star: \", P_star, \"Pe_g: \", char_domain.Pe_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b303ed",
   "metadata": {},
   "source": [
    "#### 3. Training step\n",
    "\n",
    "- first we has initializaiton for c and k net\n",
    "- then use Darcy's law to initalize p throught front tracking velocity guess\n",
    "- optimization p / p + k net through advect diffuse function.\n",
    "- joint optimize p + k + c net through data loss and advect diffuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and trainer or load from checkpoint:\n",
    "ad_dc_net = AD_DC_Net(c_layers=[4] + [cfg.c_neuron_num for _ in range(cfg.hid_layer_num)] + [1],\n",
    "        k_layers=[3] + [cfg.neuron_num for _ in range(cfg.hid_layer_num)] + [1], # if anisotropic, change to 3 output\n",
    "        p_layers=[3] + [cfg.neuron_num for _ in range(cfg.hid_layer_num)] + [1],\n",
    "        data=data, char_domain=char_domain, C_star=c_dataset.C_star,\n",
    "        K_star=k_dataset.K_star, P_star=P_star,\n",
    "        positional_encoding=cfg.use_positional_encoding,\n",
    "        freq_nums=cfg.positional_encode_nums,\n",
    "        gamma_space=cfg.position_encode_freq_scale,\n",
    "        use_learnable_D=cfg.use_learnable_D,)\n",
    "\n",
    "if cfg.do_training:\n",
    "    pinn_model = train_all_phases(ad_dc_net, DCPINN_trainer_getter, cfg)\n",
    "else:\n",
    "    checkpoint = torch.load(cfg.ckpt_path, map_location=\"cpu\")\n",
    "    if \"state_dict\" in checkpoint and \"train_phase\" in checkpoint:\n",
    "        pinn_model = DCPINN_trainer_getter(checkpoint.get(\"train_phase\"), ad_dc_net)[0]\n",
    "        pinn_model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "    else:\n",
    "        pinn_model = DCPINN_Joint(ad_dc_net, c_dataset.num_train_points)\n",
    "        ad_dc_net.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "\n",
    "# After training, visualize the learned velocity field and diffusivity\n",
    "# Extract learned parameters\n",
    "D_learned = pinn_model.ad_dc_net.D.item()\n",
    "\n",
    "print(f\"Learned diffusivity D: {D_learned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062a7d7",
   "metadata": {},
   "source": [
    "#### 4. Visualize result.\n",
    "Finally we will save the velocity mat to run GLAD (get pathline figure) in matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b83beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first visualize p and k fields\n",
    "p_fig = pinn_model.ad_dc_net.v_dc_net.p_net.draw_physical_slices(min_base=0.0)\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.imshow(p_fig)\n",
    "k_fig = pinn_model.ad_dc_net.v_dc_net.k_net.draw_physical_slices()\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.imshow(k_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1104b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract learned velocity field on a grid for visualization\n",
    "# If run out of memory, set all variables to cpu \n",
    "# pinn_model.to('cpu')\n",
    "pinn_model.to(cfg.device)\n",
    "# using mask to filter out the background vectors\n",
    "nx, ny, nz = data.shape[0], data.shape[1], data.shape[2]\n",
    "v_fig, vx,vy,vz = pinn_model.ad_dc_net.v_dc_net.draw_velocity_volume()\n",
    "# change vx,vy,vz from characteristic to mm/min then cell/min\n",
    "vx = vx * (char_domain.V_star[0] / char_domain.pixdim[0])\n",
    "vy = vy * (char_domain.V_star[1] / char_domain.pixdim[1])\n",
    "vz = vz * (char_domain.V_star[2] / char_domain.pixdim[2])\n",
    "\n",
    "_ = interactive_quiver(vx, vy, vz, pixdim, default_elev=-62.76, default_azim=-10.87)\n",
    "# print(v_fig.shape, \"\\nvx_min: \", vx.min(), \"\\tvx_max:\", vx.max(),\n",
    "#       \"\\nvy_min: \", vy.min(), \"\\tvy_max:\", vy.max(),\n",
    "#       \"\\nvz_min: \", vz.min(), \"\\tvz_max:\", vz.max())\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.imshow(v_fig)\n",
    "# use a grid (from real to characteristic) to extract velocity field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_v = np.array([vx, vy, vz]).transpose(1,2,3,0)\n",
    "frames = advect_diffuse_forward_simulation(data[:,:,:,0] / c_dataset.C_star, using_v[:,:,:,0],\n",
    "                using_v[:,:,:,1],\n",
    "                using_v[:,:,:,2],\n",
    "                D=using_D, total_time=sim_frame_num * int(t[1] - t[0]), num_steps=sim_steps_per_frame*sim_frame_num,\n",
    "                voxel_dims=(1.0,1.0,1.0))\n",
    "frames = np.array(frames).transpose(1,2,3,0)\n",
    "# jump sim_steps_per_frame to match time points\n",
    "frames = frames[:,:,:,::sim_steps_per_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a97b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with ground truth\n",
    "_ = draw_nifti_slices_with_time(frames, gt_imgs=data[:,:,:,:sim_frame_num+1] / c_dataset.C_star, brain_mask=mask, slice_along_axis='z', percentiles=(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b12f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reproduct paper, slice v_mag at x to see willis loop\n",
    "from utils.visualize import draw_nifti_slices_with_threshold, draw_colorful_slice_image\n",
    "v_mag = np.sqrt(vx**2 + vy**2 + vz**2)\n",
    "v_mag = v_mag.reshape((nx, ny, nz))\n",
    "data_t = data[:,:,:,10]\n",
    "# draw_nifti_slices_with_threshold(v_mag, brain_mask=mask, slice_along_axis='z')\n",
    "\n",
    "slices_to_show = list([43, 45, 49, 50])\n",
    "# slices_to_show = list(range(10, 15, 1))\n",
    "num_slices = len(slices_to_show)\n",
    "fig, axes = plt.subplots(1, num_slices, figsize=(num_slices * 2, 3))\n",
    "# Loop through the slices and plot on the corresponding subplot axis\n",
    "for i, x in enumerate(slices_to_show):\n",
    "    ax = axes[i]\n",
    "    rbg_img = draw_colorful_slice_image(v_mag[x,:,:].T, 'jet') # HWC\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"x={x}\")\n",
    "    ax.imshow(rbg_img)\n",
    "fig.suptitle(\"Velocity magnitude at different x slices (mm/min)\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for suptitle\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extract all density field with x,y,z,t 4D grid for visualization\n",
    "\n",
    "grid_tensor_4d = char_domain.get_characteristic_geotimedomain()  # include time part\n",
    "print(grid_tensor_4d.shape)\n",
    "def predict_concentration_4d(c_net, pts4, nx, ny, nz, nt, batch_size=200_000):\n",
    "    out_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, pts4.shape[0], batch_size):\n",
    "            chunk = pts4[i:i+batch_size]\n",
    "            pred = c_net(chunk)\n",
    "            out_list.append(pred.cpu())\n",
    "    C_flat = torch.cat(out_list, dim=0).numpy().reshape(nx, ny, nz, nt)\n",
    "    # C_flat = torch.cat(out_list, dim=0).numpy().reshape(nx, ny, nz, nt)\n",
    "    return C_flat\n",
    "\n",
    "C_pred_4d = predict_concentration_4d(pinn_model.ad_dc_net.c_net, grid_tensor_4d, nx, ny, nz, len(t), batch_size=200_000)\n",
    "# Back to physical units\n",
    "C_pred_4d *= c_dataset.C_star\n",
    "print(\"Pred shape:\", C_pred_4d.shape, \"True shape:\", data.shape)  # (nx, ny, nz, nt)\n",
    "\n",
    "_ = draw_nifti_slices_with_time(C_pred_4d, data, mask)\n",
    "# try calculate loss with true data\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# mse_overall = mean_squared_error(data.flatten(), C_pred_4d.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e373af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualized filter points from all dataset.\n",
    "if hasattr(c_dataset, \"filter_mask\"):\n",
    "    # get all point from X_train;\n",
    "    coord_xyz = char_domain.recover_length_numpy(c_dataset.X_train[0].numpy()) / char_domain.pixdim\n",
    "    coord_t = char_domain.recover_time_index(c_dataset.X_train[1].numpy())\n",
    "    vals = torch.ones((coord_t.shape[0], 1))\n",
    "    volume_seq = char_domain.points_to_geotimevolume(np.hstack((coord_xyz, coord_t)), vals.numpy())\n",
    "    draw_nifti_slices_with_time(volume_seq, None, char_domain.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get intial velocity field in cell/min for export\n",
    "init_vx = initial_velocity_field[:,:,:,0]\n",
    "init_vy = initial_velocity_field[:,:,:,1]\n",
    "init_vz = initial_velocity_field[:,:,:,2]\n",
    "\n",
    "D_factor = pinn_model.ad_dc_net.D.item() if not cfg.use_DTI else pinn_model.ad_dc_net.D_normalized.item()\n",
    "# Export velocity to .mat format so that we could run GLAD using matlab\n",
    "# the rOMT code require velocity reshaped to N*3 x 1, with unit cell/min\n",
    "save_velocity_mat(init_vx,init_vy,init_vz,pixdim, \n",
    "                  D= 0.33333, \n",
    "                  use_DTI=cfg.use_DTI,path=f\"{cfg.result_folder}/init_velocity.mat\")\n",
    "\n",
    "save_velocity_mat(vx,vy,vz,pixdim, \n",
    "                  D= D_factor, \n",
    "                  use_DTI=cfg.use_DTI,path=f\"{cfg.result_folder}/predict_velocity.mat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
