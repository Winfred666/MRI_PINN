{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3278e3",
   "metadata": {},
   "source": [
    "### Darcy Advect-diffuse net\n",
    "\n",
    "Implement the MR-AIV pipeline in [J. D. Toscano et al. 2025](https://doi.org/10.1101/2025.07.30.667741) using pytorch + lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First choose a config file to apply\n",
    "config_path = \"configs/dcpinn_full_runtest.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e4cbe",
   "metadata": {},
   "source": [
    "#### 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from modules.dc_net import AD_DC_Net\n",
    "from modules.data_module import CharacteristicDomain, DCEMRIDataModule, VelocityDataModule, PermeabilityDataModule\n",
    "from utils.config_loader import Train_Config\n",
    "from utils.train_wrapper import train_all_phases\n",
    "from utils.visualize import draw_nifti_slices_with_time, draw_nifti_slices_with_threshold, interactive_quiver\n",
    "from utils.io import load_dcemri_data, save_velocity_mat, load_DTI\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# load cfg from yaml path.\n",
    "cfg = Train_Config(config_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data,mask,pixdim,x,y,z,t = load_dcemri_data(cfg.dcemrinp_data_path)\n",
    "\n",
    "char_domain = CharacteristicDomain(data.shape, mask, t, pixdim, device)\n",
    "\n",
    "print(\"L_star: \",char_domain.L_star, \"T_star: \", char_domain.T_star)\n",
    "# batch_size is sum over data's point\n",
    "c_dataset = DCEMRIDataModule(data, char_domain,  \n",
    "                           batch_size=int(mask.sum()*len(t)), num_workers=cfg.dataset_num_workers, device=device)\n",
    "\n",
    "# set up to get num_train_points\n",
    "c_dataset.setup()\n",
    "print(\"num_train_points: \", c_dataset.num_train_points, \"batch_size: \", c_dataset.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.use_DTI:\n",
    "    DTI_tensor,DTI_MD = load_DTI(char_domain, \"data/DCE_nii_data/dti_tensor_3_3.mat\", data.shape[:3])\n",
    "else:\n",
    "    DTI_tensor = None\n",
    "\n",
    "char_domain.set_DTI_or_coef(DTI_tensor if cfg.use_DTI else 2.4e-4)\n",
    "print(\"Pe_g: \", char_domain.Pe_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622bf29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.use_DTI:\n",
    "    draw_nifti_slices_with_threshold(DTI_MD, brain_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use front-tracking to get initial velocity field.\n",
    "from utils.velocity_guess import front_tracking_velocity\n",
    "# shape (nx, ny, nz, 3), only use half of the timestep to training, consistant with c_dataset\n",
    "\n",
    "initial_velocity_field = front_tracking_velocity(data[:,:,:,::2], \n",
    "                                                 dt=t[2] - t[0])\n",
    "# scaling, front tracking give unit in grid/min, we need to scale to characteristic velocity\n",
    "initial_velocity_field *= (char_domain.pixdim / char_domain.V_star)\n",
    "\n",
    "# draw initial velocity magnitude\n",
    "vel_mag = np.linalg.norm(initial_velocity_field, axis=-1)\n",
    "# print(pixdim, char_domain.domain_shape, char_domain.L_star, char_domain.T_star, char_domain.V_star)\n",
    "print(\"velocity max and min: \", vel_mag.max(), vel_mag.min())\n",
    "draw_nifti_slices_with_threshold(vel_mag)\n",
    "\n",
    "v_dataset = VelocityDataModule(initial_velocity_field, char_domain,\n",
    "                              batch_size=int(mask.sum()), num_workers=cfg.dataset_num_workers, device=device)\n",
    "# set up to get num_train_points\n",
    "v_dataset.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720de574",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_quiver(initial_velocity_field[:,:,:,0], initial_velocity_field[:,:,:,1], \n",
    "                   initial_velocity_field[:,:,:,2], char_domain.pixdim,default_elev=-62.76, default_azim=-10.87)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f21f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.permeability_guess import estimate_initial_permeability\n",
    "\n",
    "initial_permeability, smooth_permeability = estimate_initial_permeability(data, t, ser_threshold=12.0,\n",
    "                                                     time_threshold_min=t[4])\n",
    "print(\"Initial permeability max and min: \", smooth_permeability.max(), smooth_permeability.min())\n",
    "draw_nifti_slices_with_threshold(smooth_permeability, brain_mask=mask)\n",
    "# prepare permeability datamodule, according to the paper,\n",
    "# \"smooth\" initial permeability guess is almost certainly the better and safer choice for initializing the NN_k network\n",
    "k_dataset = PermeabilityDataModule(smooth_permeability, char_domain,\n",
    "                                  batch_size=int(mask.sum()), num_workers=cfg.dataset_num_workers, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d580f",
   "metadata": {},
   "source": [
    "#### 2. Network definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4303f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.c_trainer import CNet_Init, CNet_DenoiseInit\n",
    "\n",
    "from modules.dc_trainer import DCPINN_InitK, DCPINN_InitP, DCPINN_ADPDE_P, DCPINN_ADPDE_P_K, DCPINN_Joint\n",
    "\n",
    "# write a trainner getter to factorize.\n",
    "\n",
    "def DCPINN_trainer_getter(train_phase, ad_dc_net, phase_cfg=None):\n",
    "    if train_phase == CNet_Init.train_phase:\n",
    "        pinn_model = CNet_Init(ad_dc_net.c_net, c_dataset.num_train_points)\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == CNet_DenoiseInit.train_phase:\n",
    "        pinn_model = CNet_DenoiseInit(ad_dc_net.c_net, c_dataset.num_train_points)\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == DCPINN_InitK.train_phase:\n",
    "        pinn_model = DCPINN_InitK(ad_dc_net, k_dataset.num_train_points)\n",
    "        datamodule = k_dataset\n",
    "    elif train_phase == DCPINN_InitP.train_phase:\n",
    "        pinn_model = DCPINN_InitP(ad_dc_net, v_dataset.num_train_points)\n",
    "        datamodule = v_dataset\n",
    "    elif train_phase == DCPINN_ADPDE_P.train_phase:\n",
    "        pinn_model = DCPINN_ADPDE_P(ad_dc_net, c_dataset.num_train_points)\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == DCPINN_ADPDE_P_K.train_phase:\n",
    "        pinn_model = DCPINN_ADPDE_P_K(ad_dc_net, c_dataset.num_train_points)\n",
    "        datamodule = c_dataset\n",
    "    elif train_phase == DCPINN_Joint.train_phase:\n",
    "        pinn_model = DCPINN_Joint(ad_dc_net, c_dataset.num_train_points)\n",
    "        datamodule = c_dataset\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown train_phase {train_phase}\")\n",
    "    return pinn_model, datamodule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39415700",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_star = np.mean(char_domain.V_star * cfg.viscosity * char_domain.L_star / k_dataset.K_star)\n",
    "print(\"P_star: \", P_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b303ed",
   "metadata": {},
   "source": [
    "#### 3. Training step\n",
    "\n",
    "- first we has initializaiton for c and v net\n",
    "- then pde loss for only v net\n",
    "- finally joint optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model and trainer or load from checkpoint:\n",
    "ad_dc_net = AD_DC_Net(c_layers=[4] + [cfg.neuron_num for _ in range(cfg.hid_layer_num)] + [1],\n",
    "        k_layers=[3] + [cfg.neuron_num for _ in range(cfg.hid_layer_num)] + [1], # if anisotropic, change to 3 output\n",
    "        p_layers=[3] + [cfg.neuron_num for _ in range(cfg.hid_layer_num)] + [1],\n",
    "        data=data, char_domain=char_domain, C_star=c_dataset.C_star,\n",
    "        K_star=k_dataset.K_star, P_star=P_star,\n",
    "        positional_encoding=cfg.use_positional_encoding,\n",
    "        freq_nums=cfg.positional_encode_nums,\n",
    "        gamma_space=cfg.position_encode_freq_scale,\n",
    "        anisotropic=False)\n",
    "\n",
    "if cfg.do_training:\n",
    "    pinn_model = train_all_phases(ad_dc_net, DCPINN_trainer_getter, cfg)\n",
    "else:\n",
    "    checkpoint = torch.load(cfg.ckpt_path, map_location=\"cpu\")\n",
    "    if \"state_dict\" in checkpoint:\n",
    "        pinn_model = DCPINN_trainer_getter(checkpoint.get(\"train_phase\"), ad_dc_net)[0]\n",
    "        pinn_model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "    else:\n",
    "        pinn_model = DCPINN_Joint(ad_dc_net, c_dataset.num_train_points)\n",
    "        ad_dc_net.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "\n",
    "# After training, visualize the learned velocity field and diffusivity\n",
    "# Extract learned parameters\n",
    "D_learned = pinn_model.ad_dc_net.D.item()\n",
    "\n",
    "print(f\"Learned diffusivity D: {D_learned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062a7d7",
   "metadata": {},
   "source": [
    "#### 4. Visualize result.\n",
    "Finally we will save the velocity mat to run GLAD (get pathline figure) in matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8335fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice smooth_permeability and draw it\n",
    "from utils.visualize import draw_colorful_slice_image\n",
    "val_slice_z = [char_domain.domain_shape[2] // 2 - 6, char_domain.domain_shape[2] // 2, char_domain.domain_shape[2] // 2 + 6]\n",
    "slices = smooth_permeability[:,:,val_slice_z]\n",
    "vis_k_list = []\n",
    "for i in range(slices.shape[2]):\n",
    "    vis_k = draw_colorful_slice_image(slices[:,:,i], cmap='cool', mask=char_domain.mask[:,:,val_slice_z[i]])\n",
    "    vis_k_list.append(vis_k)\n",
    "# draw learned permeability\n",
    "k_fig = np.concatenate(vis_k_list, axis=1)\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.imshow(k_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b83beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first visualize p and k fields\n",
    "p_fig = pinn_model.ad_dc_net.v_dc_net.p_net.draw_pressure_slices()\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.imshow(p_fig)\n",
    "k_fig = pinn_model.ad_dc_net.v_dc_net.k_net.draw_permeability_volume()\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.imshow(k_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1104b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Extract learned velocity field on a grid for visualization\n",
    "pinn_model.to(device)\n",
    "# using mask to filter out the background vectors\n",
    "# _ = interactive_quiver(vx, vy, vz, pixdim, default_elev=-62.76, default_azim=-10.87)\n",
    "nx, ny, nz = data.shape[0], data.shape[1], data.shape[2]\n",
    "v_fig, vx,vy,vz = pinn_model.ad_dc_net.v_dc_net.draw_velocity_volume()\n",
    "# change vx,vy,vz from characteristic to mm/min then cell/min\n",
    "vx = vx * (char_domain.V_star[0] / char_domain.pixdim[0])\n",
    "vy = vy * (char_domain.V_star[1] / char_domain.pixdim[1])\n",
    "vz = vz * (char_domain.V_star[2] / char_domain.pixdim[2])\n",
    "print(v_fig.shape, \"\\nvx_min: \", vx.min(), \"\\tvx_max:\", vx.max(),\n",
    "      \"\\nvy_min: \", vy.min(), \"\\tvy_max:\", vy.max(),\n",
    "      \"\\nvz_min: \", vz.min(), \"\\tvz_max:\", vz.max())\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(v_fig)\n",
    "# use a grid (from real to characteristic) to extract velocity field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extract all density field with x,y,z,t 4D grid for visualization\n",
    "\n",
    "grid_tensor_4d = char_domain.get_characteristic_geotimedomain()  # include time part\n",
    "print(grid_tensor_4d.shape)\n",
    "def predict_concentration_4d(c_net, pts4, nx, ny, nz, nt, batch_size=200_000):\n",
    "    out_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, pts4.shape[0], batch_size):\n",
    "            chunk = pts4[i:i+batch_size]\n",
    "            pred = c_net(chunk)\n",
    "            out_list.append(pred.cpu())\n",
    "    C_flat = torch.cat(out_list, dim=0).numpy().reshape(nx, ny, nz, nt)\n",
    "    # C_flat = torch.cat(out_list, dim=0).numpy().reshape(nx, ny, nz, nt)\n",
    "    return C_flat\n",
    "\n",
    "C_pred_4d = predict_concentration_4d(pinn_model.ad_dc_net.c_net, grid_tensor_4d, nx, ny, nz, len(t), batch_size=200_000)\n",
    "\n",
    "# Back to physical units\n",
    "C_pred_4d *= c_dataset.C_star\n",
    "print(\"Pred shape:\", C_pred_4d.shape, \"True shape:\", data.shape)  # (nx, ny, nz, nt)\n",
    "\n",
    "_ = draw_nifti_slices_with_time(C_pred_4d, data, mask)\n",
    "# try calculate loss with true data\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# mse_overall = mean_squared_error(data.flatten(), C_pred_4d.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export velocity to .mat format so that we could run GLAD using matlab\n",
    "# the rOMT code require velocity reshaped to N*3 x 1, with unit cell/min\n",
    "save_velocity_mat(vx,vy,vz,pixdim, \n",
    "                  D=pinn_model.ad_dc_net.D.item() if not cfg.use_DTI else pinn_model.ad_dc_net.D_normalized.item(), \n",
    "                  use_DTI=cfg.use_DTI,path=f\"{cfg.result_folder}/predict_velocity.mat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
