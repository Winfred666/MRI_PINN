# the default output folder name in <results>
# is the config file name without extension.

# --- Training Control ---
# If false, load a model from ckpt_path for inference without training.
do_training: true

# If true, resume training from the specified checkpoint.
continue_training: false

ckpt_path: "MRI_PINN/results/dcpinn_denoise_ISO52_H100_251017_1240/adpinn_init_p_data.pth"

# Use mri_dataset_generator.ipynb to generate the downsampled dataset.
dcemrinp_data_path: "data/ISO052_DCE_nii_data/dataset_downsampled.npz"

# Path to the checkpoint file for continuing training or for inference.

# --- Model Architecture ---
neuron_num: 150
c_neuron_num: 200
hid_layer_num: 5

# --- Feature Engineering ---
positional_encoding:
  use: true
  freq_nums: [20, 20, 20, 0] # Frequencies for (x, y, z, t)
  freq_scale: 1.0

cuda_visible_devices: [0]

# --- Physics & PDE Configuration ---
use_DTI: true
dti_data_path: "data/ISO052_DCE_nii_data/dti_tensor_3_3.mat"

use_learnable_D: false
incompressible: true
# If true, use the Diffusion Tensor Imaging data for anisotropic diffusion.
# If false, a single learnable isotropic diffusion coefficient is used.
viscosity: 6.95e-4

# --- RBAR (Residual-Based Attention Resampling) ---
enable_rbar: true
# If true, enables RBAR to focus training on points with higher loss.
# This can slow down training epochs but may lead to faster convergence.

# --- Dataloader & Checkpointing Settings ---
reload_dataloaders_every_n_epochs: 100
# How often to re-evaluate RBAR weights. Set to 0 if RBAR is disabled.

ckpt_save_val_interval: 200
# How often to run validation and save checkpoints (in epochs).

dataset_num_workers: 32
# Number of worker processes for loading data.

# --- Training Phases ---
# Define the sequence of training stages. The keys determine the order.
phases:
  # init_c_data:
  #   learning_rate: 0.0005
  #   max_epochs: 4000
  #   batch_size: 600000

  init_c_denoise_data:
    learning_rate: 0.002
    max_epochs: 10000
    batch_size: 700000

  init_k_data:
    learning_rate: 0.002
    max_epochs: 4000
    batch_size: 700000

  init_p_data:
    learning_rate: 0.002
    max_epochs: 1500
    batch_size: 700000

  filter:
    batch_size: 200000

  ad_pde_p:
    learning_rate: 0.0005
    max_epochs: 4000
    batch_size: 680000

  ad_pde_p_k:
    learning_rate: 0.00005
    max_epochs: 2000
    batch_size: 680000

  joint_data+joint_ad_pde:
    learning_rate: 0.00008
    max_epochs: 8000
    batch_size: 680000
