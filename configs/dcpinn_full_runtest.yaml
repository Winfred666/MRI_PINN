# the default output folder name in <results> 
# is the config file name without extension. 

# --- Training Control ---
# If false, load a model from ckpt_path for inference without training.
do_training: true

# If true, resume training from the specified checkpoint.
continue_training: true

ckpt_path: "results/dcpinn_full_runtest_251008_1722/adpinn_init_p_data.pth"

# Use mri_dataset_generator.ipynb to generate the downsampled dataset.
dcemrinp_data_path: "data/dataset_downsampled.npz"

# Path to the checkpoint file for continuing training or for inference.

# --- Model Architecture ---
neuron_num: 150
hid_layer_num: 5

# --- Feature Engineering ---
positional_encoding:
  use: true
  freq_nums: [20, 20, 20, 0] # Frequencies for (x, y, z, t)
  freq_scale: 1.0

# --- Physics & PDE Configuration ---
use_DTI: true
dti_data_path: "data/dti_sample.nii.gz"
# If true, use the Diffusion Tensor Imaging data for anisotropic diffusion.
# If false, a single learnable isotropic diffusion coefficient is used.

viscosity: 6.95e-4 # for characteristic permeability domain


# --- RBAR (Residual-Based Attention Resampling) ---
enable_rbar: true
# If true, enables RBAR to focus training on points with higher loss.
# This can slow down training epochs but may lead to faster convergence.

# --- Dataloader & Checkpointing Settings ---
reload_dataloaders_every_n_epochs: 5
# How often to re-evaluate RBAR weights. Set to 0 if RBAR is disabled.

ckpt_save_val_interval: 5
# How often to run validation and save checkpoints (in epochs).

dataset_num_workers: 18
# Number of worker processes for loading data.

# --- Training Phases ---
# Define the sequence of training stages. The keys determine the order.
phases:
  # init_c_data:
  #   learning_rate: 0.002
  #   max_epochs: 10
  #   batch_size: 100000

  # init_c_denoise_data:
  #   learning_rate: 0.002
  #   max_epochs: 10
  #   batch_size: 20000

  # init_k_data:
  #   learning_rate: 0.002
  #   max_epochs: 10
  #   batch_size: 200000

  # init_p_data:
  #   learning_rate: 0.002
  #   max_epochs: 10
  #   batch_size: 200000

  ad_pde_p:
    learning_rate: 0.002
    max_epochs: 10
    batch_size: 20000

  ad_pde_p_k:
    learning_rate: 0.002
    max_epochs: 10
    batch_size: 20000

  joint_data+joint_ad_pde:
    learning_rate: 0.0002
    max_epochs: 10
    batch_size: 18000
